{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PytorchImagePipeline","text":"<p>This is a repository for creating and running Pytorch Image Pipelines.</p>"},{"location":"#overview","title":"Overview","text":"<p>The PytorchImagePipeline is a python package, which allows the developer to create new Deep Learning approaches in as a generalized Pipeline.</p> <p>The most approaches to new experiments are script or notebook based. While this approach helps to create fast results and showcase the Experiment, it is difficult to create a robust and repeatable structure.</p> <p>The script approach often leads to not maintainable code structure. Often multiple things are done in one place, which logical are only weakly connected. As example creating visualization, providing the visualization to the experiment server and training are often applied in the same script. Combined with configuration of those elements in the same script leads to a chaotic structure.</p> <p>We might need the structure, because they were a direct execution of our thoughts, which are also just came up while creating the first prototype of the experiment. But melting this chaos into a more structured and organized environment, often seems a huge effort. An effort where we might think it isn't worth it.</p> <p>At exactly this point PytorchImagePipeline wants to shine. The Project provides the base structure to build structured, repeatable Experiments.</p> <p>To start the new experiment journey the developer/scientist/engineer just needs to categorize parts of the Experiments as Permanence or Process. After that, the Getting Started provide the information needed to build the structured Pipeline.</p>"},{"location":"getting_started/","title":"Getting Started","text":"<p>If you want to study how to execute already implemented pipelines, please refer Usage</p> <p>This document will teach how to create a new Pipeline, with all necessary parts.</p> <p>The document is written under the Assumption a developer has already created strong ideas, that should flow into a pipeline. This could be done on paper, script or notebook, but the final product should already kind of manifested. Better in text, but in mind is also no issue.</p> <p>As described in the Overview, the first step is to decide if a part of the pipeline is a <code>Permanence</code> or a <code>PipelineProcess</code>.</p>"},{"location":"getting_started/#internal-logic","title":"Internal logic","text":"<p>In detail the following image provides some information how the Pipeline is structured. If you do not want to read the internal logic jump straight to Create Config</p> <p></p> <p>UML Diagram sketch of <code>PytorchImagePipeline</code></p> <p>In the diagram are the three main components of the PytorchImagePipeline depicted. The <code>Observer</code> class is central part of the pipeline, storing and providing all the necessary components of the pipeline. The <code>Permanence</code> abstract class is used to create new implementations for objects which hold permanent information about the pipeline. As example a <code>Dataset</code> is a kind of information, which a process needs to access, but could be created without the flow of the pipeline. Compared to a script a <code>Dataset</code> is mostly an instance which is in the global scope. The <code>PipelineProcess</code> abstract class is the opposite to a <code>Permanence</code>. As example a <code>Visualization</code> creates a figure, which displays given batch of images as subplots with certain config. Of course, we could extract further parts of the <code>Visualization</code> as new <code>Permanence</code> implementations, as example the parameters of the figure.</p> <p>The <code>Observer</code> is instantiated with a dictionary of zero <code>Permanence</code> or more. This step is displayed as the aggregation<sup>1</sup>. Afterwards one <code>PipelineProcesse</code> or more are added to the <code>Observer</code>. This step is displayed as the composition<sup>1</sup>. The run method of the <code>Observer</code> class iterates over each <code>PipelineProcess</code> and calls it <code>execute</code> method, which uses (displayed as association<sup>1</sup>) the observer itself to access the <code>Permanence</code> if needed.</p> <p>Since doing this by hand is cumbersome and error-prone, a <code>PipelineBuilder</code> class is provided, which executes this behavior.</p>"},{"location":"getting_started/#create-config","title":"Create Config","text":"<p>After the decision which Parts fall into either the <code>Permanence</code> or the <code>PipelineProcess</code> category, the creation of the config files begins.</p> <p>It is not necessary to complete the configs at this point. The goal is to create a structure to begin with and complete later.</p> <p>Following steps are necessary to create the config structure:</p> <ol> <li>Create new folder under configs with the name of the Pipeline.</li> <li>Create <code>execute_pipeline.toml</code> file inside this folder.</li> <li>Create <code>initial_pipeline.toml</code> file inside this folder.</li> </ol>"},{"location":"getting_started/#the-initial_pipelinetoml","title":"The <code>initial_pipeline.toml</code>","text":"<p>Since not all components of a Pipeline should be part of the repository, it is necessary to provide such information.</p> <p>Following components of a Pipeline needed to be defined inside this config:</p> <ul> <li>Dependencies</li> <li>Dataset locations</li> <li>Model locations</li> </ul> <p>An Example config could look like the following:</p> <pre><code>[dependencies.submodules.sam]\nname = \"segment_anything\"\nurl = \"https://github.com/facebookresearch/segment-anything.git\"\ncommit = \"dca509fe\"\n\n[data.datasets.pascal]\nlocation = \"/mnt/data1/datasets/image/voc/VOCdevkit/VOC2012/\"\nformat = \"pascalvoc\"\n\n[data.models.sam]\nlocation = \"/mnt/data1/models/sam/sam_vit_h_4b8939.pth\"\nformat = \"pth\"\n</code></pre> <p>The dependency is in this case a git submodule, but could be also a pip package. The dependencies will be installed via <code>uv pip install</code>, so it will not interfere with <code>pyproject.toml</code>.</p> <p>A dataset and a model are always provided with a key (<code>pascal</code> or <code>sam</code> in this case), a location and a format. The key will be used to create the symlink below <code>data/dataset</code> or <code>data/models</code> based on location. The format helps to reduce Boilerplate for dataset creation.</p>"},{"location":"getting_started/#the-execute_pipelinetoml","title":"The <code>execute_pipeline.toml</code>","text":"<p>This config file is used to provide the different <code>Permanence</code> and <code>PipelineProcess</code> object configurations.</p> <p>An example config could look like the following:</p> <pre><code>[permanences.data]\ntype = \"Datasets\"\nparams = { root = \"localhost\", format = \"pascalvoc\" }\n\n[processes.viz]\ntype = \"Visualization\"\n</code></pre> <p>Here are one <code>Permanence</code> and one <code>PipelineProcess</code> object provided. The <code>params</code> field is always Optional. The <code>type</code> field provides the classes of the Pipeline, which we need to create inside our Pipeline Library. The <code>params</code> need to match accordingly to the <code>__init__</code> method of the Implementation.</p> <p>Additional configuration for provided <code>Permanence</code> or <code>PipelineProcess</code> classes could here be provided. As example from the core package the <code>Visualization</code> process is defined in the config. The <code>Builder</code> will first register the <code>Visualization</code> class from core package. It is also possible to override the <code>Visualization</code> class inside the pipeline library.</p>"},{"location":"getting_started/#create-pipeline-library","title":"Create Pipeline Library","text":"<p>With the initiation of the config files we can begin creating the actual pipeline library. It is necessary to create for every entry in the config its implementation, but we have the freedom to provide additional pipeline internal structure. The structure of a new pipeline subpackage looks the following:</p> <pre><code>\ud83d\udce6pytorchimagepipeline\n \u2517 \ud83d\udce6pipelines\n    \u2517 \ud83d\udce6node_modules\n       \u2523 \ud83d\udcdc__init__.py\n       \u2523 \ud83d\udcdcpermanences.py\n       \u2517 \ud83d\udcdcprocesses.py\n</code></pre> <p>Following the structure the implementations should be provided dependent on the config either inside the <code>permanences.py</code> or <code>processes.py</code> module. This is just a recommendation to follow the pattern of the package, but a developer can decide against the pattern. The only necessary part is the announcement of the <code>Permanence</code> and the <code>PipelineProcess</code> inside the subpackage <code>__init__.py</code> module.</p> <p>For the previous example the <code>__init__.py</code> module looks the following:</p> <pre><code>from permaneces import Datasets\nfrom processes import DummyProcess\n\npermanences_to_register = {\"Datasets\": Datasets}\nprocesses_to_register = {\"Visualization\": Visualization}\n</code></pre>"},{"location":"getting_started/#execute-or-testing","title":"Execute or testing","text":"<p>From that point there are initial two possible ways to proceed.</p> <ol> <li>Execute the Pipeline directly</li> </ol> <p>This could be a good start point to get familiar how the pipeline works and looks as the final product. It is good practice to follow this approach if the developer works first time with this project. Nevertheless, the second way is an absolute recommendation, to create the final pipeline.</p> <ol> <li>Creating test cases</li> </ol> <p>The creation of test cases is a recommended approach, since at the end multiple small components of the pipeline are provided. Instead of running all the time the complete pipeline, checking each bit with artificial and abstract test cases could provide spare time. Not only this, after iterating through changes in the pipeline library, we are able to verify the correctness of the step in the Pipeline. In a certain situation it might be necessary to extend the test case to fulfil new challenges, which were not thought about at the beginning of the Pipeline development.</p>"},{"location":"getting_started/#documentation","title":"Documentation","text":"<p>As the last step or in parallel while developing a new pipeline, documenting the pipeline is a key feature of this package.</p> <ul> <li>Create a new markdown file with the name of the pipeline under <code>docs/pipelines</code>.</li> <li>Fill the markdown with the description, goal and results of the pipeline.</li> <li>As example the <code>Visualization</code> could directly output images for documentation to the <code>docs/assets</code> location.</li> <li>Add the markdown file to navigation in <code>mkdocs.yml</code>:</li> </ul> <pre><code>@@ -12,7 +12,8 @@ nav:\n   - Installation: installation.md\n   - Usage: usage.md\n   - Getting Started: getting_started.md\n   - Pipelines:\n+      - new_pipeline: pipelines/new_pipeline.md\n   - Modules:\n       - builder.py: modules/builder.md\n       - observer.py: modules/observer.md\n</code></pre> <p>Additional also extending the module section is possible.</p> <ol> <li> <p>A short explanation between an aggregation vs. composition vs. association.\u00a0\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"ideas/","title":"Ideas","text":"<p>This Chapter describes Ideas to enhance the project. It can be interpreted as lists of TODOS.</p>"},{"location":"ideas/#nested-process-bars","title":"Nested Process Bars","text":"<p>Since a pipeline does have various steps we want an informative way to show the status of the current running pipeline.</p> <p>Here are two approaches for nested progress bars:</p> TQDMRICH <p>source</p> <pre><code>from tqdm import tqdm\n# from tqdm.auto import tqdm  # notebook compatible\nimport time\nfor i1 in tqdm(range(5)):\n    for i2 in tqdm(range(300), leave=False):\n        # do something, e.g. sleep\n        time.sleep(0.01)\n</code></pre> <p>source</p> <pre><code>import time\n\nfrom rich.progress import Progress\n\nwith Progress() as progress:\n\n    task1 = progress.add_task(\"[red]Downloading...\", total=1000)\n    task2 = progress.add_task(\"[green]Processing...\", total=1000)\n    task3 = progress.add_task(\"[cyan]Cooking...\", total=1000)\n\n    while not progress.finished:\n        progress.update(task1, advance=0.5)\n        progress.update(task2, advance=0.3)\n        progress.update(task3, advance=0.9)\n        time.sleep(0.02)\n</code></pre>"},{"location":"ideas/#ansolved-questions","title":"Ansolved Questions:","text":"<ul> <li>How to handle monitoring of internal loops?</li> </ul>"},{"location":"ideas/#tensorboard-process","title":"Tensorboard Process","text":"<p>A core Tensorboard process which based on config creates different visualizations.</p>"},{"location":"ideas/#wandb-process","title":"Wandb Process","text":"<p>A core Wandb process which based on config creates different visualizations and perform hyperparam trainings.</p>"},{"location":"ideas/#prerun-validation","title":"PreRun Validation","text":"<p>Since we create mostly everything dynamic from the config and only checking that the general structure of the config is correct, also validating the actual run before executing, would be beneficial. Since most Processes will access Permanences of the Observer, we could before the final execution check that every call of observer.used_permanence of every process doesn't result in a <code>NameError</code> (if <code>Permanence</code> is not defined), <code>AttributeError</code> (if <code>Permanence</code> does not have given Attribute) or <code>TypeError</code> (if <code>Permanece</code> method got not the correct Attributes).</p> <p>The Pipeline can still crash caused by internal other errors, but we ensure, that the Process will not fail caused by issue in the config.</p>"},{"location":"ideas/#init-script-cli-command-for-new-pipelines","title":"Init Script / cli command for new Pipelines","text":"<p>A init script or cli command could speed up start times.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"usage/","title":"Usage","text":""},{"location":"modules/abstractions/","title":"abstractions.py","text":"<p>This module defines abstract base classes for the Pytorch image pipeline.</p> <p>Classes:</p> Name Description <code>AbstractObserver</code> <p>Base class for the Observer class.</p> <code>Permanence</code> <p>Base class for objects that persist through the entire pipeline lifecycle.</p> <code>PipelineProcess</code> <p>Abstract base class for pipeline processes.</p> <p>Copyright (C) 2025 Matti Kaupenjohann</p> <p>This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.</p> <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.</p> <p>You should have received a copy of the GNU General Public License along with this program. If not, see https://www.gnu.org/licenses/.</p>"},{"location":"modules/abstractions/#pytorchimagepipeline.abstractions.AbstractObserver","title":"<code>AbstractObserver</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for the Observer class</p> Source code in <code>pytorchimagepipeline/abstractions.py</code> <pre><code>class AbstractObserver(ABC):\n    \"\"\"Base class for the Observer class\"\"\"\n\n    @abstractmethod\n    def run(self) -&gt; None:\n        \"\"\"Executes the observer's processes.\n\n        This method runs the specific processes defined by the observer implementation.\n        The execution details depend on the concrete observer class. #todo: add different observers\n\n        Returns:\n            None: This method doesn't return any value\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/abstractions/#pytorchimagepipeline.abstractions.AbstractObserver.run","title":"<code>run()</code>  <code>abstractmethod</code>","text":"<p>Executes the observer's processes.</p> <p>This method runs the specific processes defined by the observer implementation. The execution details depend on the concrete observer class. #todo: add different observers</p> <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This method doesn't return any value</p> Source code in <code>pytorchimagepipeline/abstractions.py</code> <pre><code>@abstractmethod\ndef run(self) -&gt; None:\n    \"\"\"Executes the observer's processes.\n\n    This method runs the specific processes defined by the observer implementation.\n    The execution details depend on the concrete observer class. #todo: add different observers\n\n    Returns:\n        None: This method doesn't return any value\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/abstractions/#pytorchimagepipeline.abstractions.Permanence","title":"<code>Permanence</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for objects that persist through the entire pipeline lifecycle</p> Source code in <code>pytorchimagepipeline/abstractions.py</code> <pre><code>class Permanence(ABC):\n    \"\"\"Base class for objects that persist through the entire pipeline lifecycle\"\"\"\n\n    @abstractmethod\n    def cleanup(self) -&gt; Optional[Exception]:\n        \"\"\"Cleans up data from RAM or VRAM.\n\n        Since the objects are permanent, it might be necessary to call a cleanup.\n        This will be executed by the observer.\n\n        Returns:\n            Optional[Exception]: An exception if an error occurs during cleanup, otherwise None.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/abstractions/#pytorchimagepipeline.abstractions.Permanence.cleanup","title":"<code>cleanup()</code>  <code>abstractmethod</code>","text":"<p>Cleans up data from RAM or VRAM.</p> <p>Since the objects are permanent, it might be necessary to call a cleanup. This will be executed by the observer.</p> <p>Returns:</p> Type Description <code>Optional[Exception]</code> <p>Optional[Exception]: An exception if an error occurs during cleanup, otherwise None.</p> Source code in <code>pytorchimagepipeline/abstractions.py</code> <pre><code>@abstractmethod\ndef cleanup(self) -&gt; Optional[Exception]:\n    \"\"\"Cleans up data from RAM or VRAM.\n\n    Since the objects are permanent, it might be necessary to call a cleanup.\n    This will be executed by the observer.\n\n    Returns:\n        Optional[Exception]: An exception if an error occurs during cleanup, otherwise None.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/abstractions/#pytorchimagepipeline.abstractions.PipelineProcess","title":"<code>PipelineProcess</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for pipeline processes</p> Source code in <code>pytorchimagepipeline/abstractions.py</code> <pre><code>class PipelineProcess(ABC):\n    \"\"\"Abstract base class for pipeline processes\"\"\"\n\n    @abstractmethod\n    def execute(self, observer: AbstractObserver) -&gt; Optional[Exception]:\n        \"\"\"Executes the process.\n\n        Args:\n            observer (AbstractObserver): The observer instance managing the pipeline.\n\n        Returns:\n            Optional[Exception]: An exception if an error occurs during execution, otherwise None.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/abstractions/#pytorchimagepipeline.abstractions.PipelineProcess.execute","title":"<code>execute(observer)</code>  <code>abstractmethod</code>","text":"<p>Executes the process.</p> <p>Parameters:</p> Name Type Description Default <code>observer</code> <code>AbstractObserver</code> <p>The observer instance managing the pipeline.</p> required <p>Returns:</p> Type Description <code>Optional[Exception]</code> <p>Optional[Exception]: An exception if an error occurs during execution, otherwise None.</p> Source code in <code>pytorchimagepipeline/abstractions.py</code> <pre><code>@abstractmethod\ndef execute(self, observer: AbstractObserver) -&gt; Optional[Exception]:\n    \"\"\"Executes the process.\n\n    Args:\n        observer (AbstractObserver): The observer instance managing the pipeline.\n\n    Returns:\n        Optional[Exception]: An exception if an error occurs during execution, otherwise None.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/builder/","title":"builder.py","text":"<p>This module provides the implementation of the PipelineBuilder class, which is responsible for building and configuring a pipeline of processes and permanences for the PytorchImagePipeline project.</p> <p>The PipelineBuilder class allows for the registration of classes, loading of configuration files, validation of configuration sections, and construction of the complete pipeline. It handles errors related to configuration loading, class instantiation, and process addition.</p> <p>Classes:</p> Name Description <code>PipelineBuilder</code> <p>A class to build and configure a pipeline of processes and permanences.</p> <p>Functions:</p> Name Description <code>get_objects_for_pipeline</code> <p>str) -&gt; dict[str, type]: Retrieves and combines objects to be registered for a given pipeline.</p> <p>Usage Example:</p>"},{"location":"modules/builder/#pytorchimagepipeline.builder--todo-add-usage-example","title":"TODO: Add usage example","text":"<p>Copyright (C) 2025 Matti Kaupenjohann</p> <p>This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.</p> <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.</p> <p>You should have received a copy of the GNU General Public License along with this program. If not, see https://www.gnu.org/licenses/.</p>"},{"location":"modules/builder/#pytorchimagepipeline.builder.PipelineBuilder","title":"<code>PipelineBuilder</code>","text":"Source code in <code>pytorchimagepipeline/builder.py</code> <pre><code>class PipelineBuilder:\n    def __init__(self) -&gt; None:\n        \"\"\"\n        Initializes the builder with empty configuration and class registry.\n\n        Attributes:\n            _config (dict[str, Any]): A dictionary to store configuration settings.\n            _class_registry (dict[str, type]): A dictionary to store class types by name.\n        \"\"\"\n        self._config: dict[str, Any] = {}\n        self._class_registry: dict[str, type] = {}\n\n    def register_class(self, name: str, cls: type) -&gt; None | Exception:\n        \"\"\"\n        Registers a class in the class registry.\n\n        Args:\n            name (str): The name to register the class under.\n            cls (type): The class type to register.\n\n        Returns:\n            Optional[Exception]: Returns a RegistryError if the class is not a subclass\n                                 of either Permanence or PipelineProcess, otherwise None.\n        \"\"\"\n        if not issubclass(cls, (Permanence, PipelineProcess)):\n            return RegistryError(name)\n        self._class_registry[name] = cls\n        return None\n\n    def load_config(self, config_path: Path) -&gt; None | Exception:\n        \"\"\"\n        Loads a configuration file from the specified path.\n\n        Args:\n            config_path (Path): The path to the configuration file.\n\n        Returns:\n            Optional[Exception]: Returns an exception if an error occurs during loading,\n                     otherwise returns None.\n\n        Raises:\n            ConfigNotFoundError: If the configuration file does not exist.\n            ConfigPermissionError: If the configuration file is not readable.\n            ConfigInvalidTomlError: If the configuration file is not a valid TOML file.\n        \"\"\"\n        config_path_extended = Path(\"configs\") / config_path\n        if not config_path_extended.exists():\n            return ConfigNotFoundError(config_path_extended)\n        if not os.access(config_path_extended, os.R_OK):\n            return ConfigPermissionError(config_path_extended)\n        with open(config_path_extended, \"rb\") as f:\n            try:\n                self._config |= toml_load(f)\n            except TOMLDecodeError:\n                return ConfigInvalidTomlError(config_path_extended)\n        error = self._validate_config_sections()\n        return error\n\n    def _validate_config_sections(self) -&gt; None | Exception:\n        \"\"\"\n        Validate required configuration sections.\n\n        This method checks if the required sections are present in the configuration.\n        If any required section is missing, it returns a ConfigSectionError for the missing section.\n\n        Returns:\n            Optional[Exception]: ConfigSectionError if a required section is missing, otherwise None.\n        \"\"\"\n        required_sections = [\"permanences\", \"processes\"]\n        for section in required_sections:\n            if section not in self._config:\n                return ConfigSectionError(section)\n        return None\n\n    def build(self) -&gt; tuple[Observer, None | Exception]:\n        \"\"\"\n        Construct the complete pipeline.\n\n        Returns:\n            tuple[Observer, Optional[Exception]]: A tuple containing the constructed Observer object\n            and an optional Exception if an error occurred during the construction process.\n        \"\"\"\n        permanence, error = self._build_permanences()\n        if error:\n            return Observer(permanences={}), error\n        observer = Observer(permanences=permanence)\n        error = self._build_processes(observer)\n        if error:\n            return observer, error\n        return observer, None\n\n    def _build_permanences(self) -&gt; tuple[dict[str, Permanence], None | Exception]:\n        \"\"\"\n        Construct permanence objects with error handling.\n\n        This method iterates over the permanence configurations provided in\n        `self._config[\"permanences\"]`, instantiates each permanence object,\n        and collects them into a dictionary. If an error occurs during the\n        instantiation of any permanence object, the method returns an empty\n        dictionary and the encountered error.\n\n        Returns:\n            tuple[dict[str, Permanence], Optional[Exception]]: A tuple containing:\n                - A dictionary where keys are permanence names and values are\n                  the instantiated permanence objects.\n                - An optional Exception if an error occurred during instantiation,\n                  otherwise None.\n        \"\"\"\n        objects: dict[str, Permanence] = {}\n        for name, config in self._config[\"permanences\"].items():\n            instance, error = self._instantiate_from_config(name, config)\n            if error:\n                return {}, error\n            if isinstance(instance, Permanence):\n                objects[name] = instance\n        return objects, None\n\n    def _build_processes(self, observer: Observer) -&gt; None | Exception:\n        \"\"\"\n        Builds and adds processes to the observer based on the configuration.\n\n        Args:\n            observer (Observer): The observer to which the processes will be added.\n\n        Returns:\n            Optional[Exception]: Returns an exception if an error occurs during the\n            instantiation or addition of a process, otherwise returns None.\n        \"\"\"\n        for name, config in self._config[\"processes\"].items():\n            process, error = self._instantiate_from_config(name, config)\n            if error:\n                return error\n            if not isinstance(process, PipelineProcess):\n                return InstTypeError(process)\n            observer.add_process(process)\n        return None\n\n    def _instantiate_from_config(\n        self, context: str, config: dict[str, Any]\n    ) -&gt; tuple[Permanence | PipelineProcess | None, None | Exception]:\n        \"\"\"\n        Instantiate an object from a configuration dictionary.\n\n        Args:\n            context (str): The context or name of the configuration.\n            config (dict[str, Any]): The configuration dictionary containing the type and parameters.\n\n        Returns:\n            tuple[Permanence | PipelineProcess, Optional[Exception]]:\n            - An instance of the class specified in the configuration if successful.\n            - None and an appropriate exception if instantiation fails.\n\n        Raises:\n            InstTypeError: If the \"type\" key is not present in the configuration.\n            RegistryError: If the class name specified in the configuration is not found in the class registry.\n            RegistryParamError: If there is a TypeError during instantiation, likely due to incorrect parameters.\n        \"\"\"\n        if \"type\" not in config:\n            return None, InstTypeError(context)\n        cls_name = config[\"type\"]\n        params = config.get(\"params\", {})\n        if cls_name not in self._class_registry:\n            return None, RegistryError(f\"{context}-{cls_name}\")\n        try:\n            return self._class_registry[cls_name](**params), None\n        except TypeError:\n            return None, RegistryParamError(params)\n</code></pre>"},{"location":"modules/builder/#pytorchimagepipeline.builder.PipelineBuilder.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the builder with empty configuration and class registry.</p> <p>Attributes:</p> Name Type Description <code>_config</code> <code>dict[str, Any]</code> <p>A dictionary to store configuration settings.</p> <code>_class_registry</code> <code>dict[str, type]</code> <p>A dictionary to store class types by name.</p> Source code in <code>pytorchimagepipeline/builder.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"\n    Initializes the builder with empty configuration and class registry.\n\n    Attributes:\n        _config (dict[str, Any]): A dictionary to store configuration settings.\n        _class_registry (dict[str, type]): A dictionary to store class types by name.\n    \"\"\"\n    self._config: dict[str, Any] = {}\n    self._class_registry: dict[str, type] = {}\n</code></pre>"},{"location":"modules/builder/#pytorchimagepipeline.builder.PipelineBuilder.build","title":"<code>build()</code>","text":"<p>Construct the complete pipeline.</p> <p>Returns:</p> Type Description <code>Observer</code> <p>tuple[Observer, Optional[Exception]]: A tuple containing the constructed Observer object</p> <code>None | Exception</code> <p>and an optional Exception if an error occurred during the construction process.</p> Source code in <code>pytorchimagepipeline/builder.py</code> <pre><code>def build(self) -&gt; tuple[Observer, None | Exception]:\n    \"\"\"\n    Construct the complete pipeline.\n\n    Returns:\n        tuple[Observer, Optional[Exception]]: A tuple containing the constructed Observer object\n        and an optional Exception if an error occurred during the construction process.\n    \"\"\"\n    permanence, error = self._build_permanences()\n    if error:\n        return Observer(permanences={}), error\n    observer = Observer(permanences=permanence)\n    error = self._build_processes(observer)\n    if error:\n        return observer, error\n    return observer, None\n</code></pre>"},{"location":"modules/builder/#pytorchimagepipeline.builder.PipelineBuilder.load_config","title":"<code>load_config(config_path)</code>","text":"<p>Loads a configuration file from the specified path.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>Path</code> <p>The path to the configuration file.</p> required <p>Returns:</p> Type Description <code>None | Exception</code> <p>Optional[Exception]: Returns an exception if an error occurs during loading,      otherwise returns None.</p> <p>Raises:</p> Type Description <code>ConfigNotFoundError</code> <p>If the configuration file does not exist.</p> <code>ConfigPermissionError</code> <p>If the configuration file is not readable.</p> <code>ConfigInvalidTomlError</code> <p>If the configuration file is not a valid TOML file.</p> Source code in <code>pytorchimagepipeline/builder.py</code> <pre><code>def load_config(self, config_path: Path) -&gt; None | Exception:\n    \"\"\"\n    Loads a configuration file from the specified path.\n\n    Args:\n        config_path (Path): The path to the configuration file.\n\n    Returns:\n        Optional[Exception]: Returns an exception if an error occurs during loading,\n                 otherwise returns None.\n\n    Raises:\n        ConfigNotFoundError: If the configuration file does not exist.\n        ConfigPermissionError: If the configuration file is not readable.\n        ConfigInvalidTomlError: If the configuration file is not a valid TOML file.\n    \"\"\"\n    config_path_extended = Path(\"configs\") / config_path\n    if not config_path_extended.exists():\n        return ConfigNotFoundError(config_path_extended)\n    if not os.access(config_path_extended, os.R_OK):\n        return ConfigPermissionError(config_path_extended)\n    with open(config_path_extended, \"rb\") as f:\n        try:\n            self._config |= toml_load(f)\n        except TOMLDecodeError:\n            return ConfigInvalidTomlError(config_path_extended)\n    error = self._validate_config_sections()\n    return error\n</code></pre>"},{"location":"modules/builder/#pytorchimagepipeline.builder.PipelineBuilder.register_class","title":"<code>register_class(name, cls)</code>","text":"<p>Registers a class in the class registry.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to register the class under.</p> required <code>cls</code> <code>type</code> <p>The class type to register.</p> required <p>Returns:</p> Type Description <code>None | Exception</code> <p>Optional[Exception]: Returns a RegistryError if the class is not a subclass                  of either Permanence or PipelineProcess, otherwise None.</p> Source code in <code>pytorchimagepipeline/builder.py</code> <pre><code>def register_class(self, name: str, cls: type) -&gt; None | Exception:\n    \"\"\"\n    Registers a class in the class registry.\n\n    Args:\n        name (str): The name to register the class under.\n        cls (type): The class type to register.\n\n    Returns:\n        Optional[Exception]: Returns a RegistryError if the class is not a subclass\n                             of either Permanence or PipelineProcess, otherwise None.\n    \"\"\"\n    if not issubclass(cls, (Permanence, PipelineProcess)):\n        return RegistryError(name)\n    self._class_registry[name] = cls\n    return None\n</code></pre>"},{"location":"modules/builder/#pytorchimagepipeline.builder.get_objects_for_pipeline","title":"<code>get_objects_for_pipeline(pipeline_name)</code>","text":"<p>Retrieves and combines objects to be registered for a given pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline_name</code> <code>str</code> <p>The name of the pipeline for which to retrieve objects.</p> required <p>Returns:</p> Type Description <code>tuple[dict[str, type], None | Exception]</code> <p>dict[str, type]: A dictionary containing the combined objects from              <code>permanences_to_register</code> and <code>processes_to_register</code>              of the specified pipeline module.</p> Source code in <code>pytorchimagepipeline/builder.py</code> <pre><code>def get_objects_for_pipeline(pipeline_name: str) -&gt; tuple[dict[str, type], None | Exception]:\n    \"\"\"\n    Retrieves and combines objects to be registered for a given pipeline.\n\n    Args:\n        pipeline_name (str): The name of the pipeline for which to retrieve objects.\n\n    Returns:\n        dict[str, type]: A dictionary containing the combined objects from\n                         `permanences_to_register` and `processes_to_register`\n                         of the specified pipeline module.\n    \"\"\"\n    full_module_name = \"pytorchimagepipeline.pipelines.\" + pipeline_name\n    try:\n        module = importlib.import_module(full_module_name)\n    except ModuleNotFoundError as e:\n        return {}, e\n    return module.permanences_to_register | module.processes_to_register, None\n</code></pre>"},{"location":"modules/errors/","title":"errors.py","text":"<p>Error handling for pytorch image pipeline.</p> <p>This module implements error handling for configuration, registry and execution of the pipeline.</p> <p>Copyright (C) 2025 Matti Kaupenjohann</p> <p>This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.</p> <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.</p> <p>You should have received a copy of the GNU General Public License along with this program. If not, see https://www.gnu.org/licenses/.</p>"},{"location":"modules/errors/#pytorchimagepipeline.errors.ConfigInvalidTomlError","title":"<code>ConfigInvalidTomlError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised when the configuration file is not valid toml</p> Source code in <code>pytorchimagepipeline/errors.py</code> <pre><code>class ConfigInvalidTomlError(BuilderError):\n    \"\"\"Raised when the configuration file is not valid toml\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        super().__post_init__(ErrorCode.CONFIG_INVALID)\n</code></pre>"},{"location":"modules/errors/#pytorchimagepipeline.errors.ConfigNotFoundError","title":"<code>ConfigNotFoundError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised when the builder configuration file does not exists</p> Source code in <code>pytorchimagepipeline/errors.py</code> <pre><code>class ConfigNotFoundError(BuilderError):\n    \"\"\"Raised when the builder configuration file does not exists\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        super().__post_init__(ErrorCode.CONFIG_MISSING)\n</code></pre>"},{"location":"modules/errors/#pytorchimagepipeline.errors.ConfigPermissionError","title":"<code>ConfigPermissionError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised when the builder configuration file does not exists</p> Source code in <code>pytorchimagepipeline/errors.py</code> <pre><code>class ConfigPermissionError(BuilderError):\n    \"\"\"Raised when the builder configuration file does not exists\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        super().__post_init__(ErrorCode.CONFIG_PERMISSION)\n</code></pre>"},{"location":"modules/errors/#pytorchimagepipeline.errors.ConfigSectionError","title":"<code>ConfigSectionError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised for config section missing</p> Source code in <code>pytorchimagepipeline/errors.py</code> <pre><code>class ConfigSectionError(BuilderError):\n    \"\"\"Raised for config section missing\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        super().__post_init__(ErrorCode.CONFIG_SECTION)\n</code></pre>"},{"location":"modules/errors/#pytorchimagepipeline.errors.ExecutionError","title":"<code>ExecutionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised during process execution failures</p> Source code in <code>pytorchimagepipeline/errors.py</code> <pre><code>class ExecutionError(Exception):\n    \"\"\"Raised during process execution failures\"\"\"\n\n    def __init__(self, process: str, error: Exception):\n        error_code = ErrorCode.PROCESS_EXECUTION\n        super().__init__(f\"[{error_code.code}]: Process {process} failed with {error}\")\n</code></pre>"},{"location":"modules/errors/#pytorchimagepipeline.errors.InstTypeError","title":"<code>InstTypeError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised when type in config not set</p> Source code in <code>pytorchimagepipeline/errors.py</code> <pre><code>class InstTypeError(BuilderError):\n    \"\"\"Raised when type in config not set\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        super().__post_init__(ErrorCode.INST_TYPE)\n</code></pre>"},{"location":"modules/errors/#pytorchimagepipeline.errors.RegistryError","title":"<code>RegistryError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised for class registration issues</p> Source code in <code>pytorchimagepipeline/errors.py</code> <pre><code>class RegistryError(BuilderError):\n    \"\"\"Raised for class registration issues\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        super().__post_init__(ErrorCode.REGISTRY_INVALID)\n</code></pre>"},{"location":"modules/errors/#pytorchimagepipeline.errors.RegistryParamError","title":"<code>RegistryParamError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised for class instatioation with wrong params</p> Source code in <code>pytorchimagepipeline/errors.py</code> <pre><code>class RegistryParamError(BuilderError):\n    \"\"\"Raised for class instatioation with wrong params\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        super().__post_init__(ErrorCode.REGISTRY_PARAM)\n</code></pre>"},{"location":"modules/observer/","title":"observer.py","text":"<p>This module defines an Observer responsible for managing a pipeline of processes and handling potential errors that occur during their execution.</p> <p>Classes:</p> Name Description <code>Observer</code> <p>Manages a pipeline of processes and handles errors that occur during.</p> <p>Copyright (C) 2025 Matti Kaupenjohann</p> <p>This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.</p> <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.</p> <p>You should have received a copy of the GNU General Public License along with this program. If not, see https://www.gnu.org/licenses/.</p>"},{"location":"modules/observer/#pytorchimagepipeline.observer.Observer","title":"<code>Observer</code>","text":"<p>               Bases: <code>AbstractObserver</code></p> Source code in <code>pytorchimagepipeline/observer.py</code> <pre><code>class Observer(AbstractObserver):\n    def __init__(self, permanences: dict[str, Permanence]):\n        \"\"\"\n        Initializes the Observer with the given permanences.\n\n        Args:\n            permanences (dict[str, Permanence]): A dictionary mapping string keys to Permanence objects.\n        \"\"\"\n        self._permanences = permanences\n        self._processes: list[PipelineProcess] = []\n        self._current_process: Optional[PipelineProcess] = None\n\n    def add_process(self, process: PipelineProcess) -&gt; None:\n        \"\"\"Adds a process to the pipeline.\n\n        Args:\n            process (PipelineProcess): The process to add.\n        \"\"\"\n        self._processes.append(process)\n\n    def run(self) -&gt; None:\n        \"\"\"\n        Executes each process in the list of processes.\n\n        Iterates over the processes, sets the current process, and executes it.\n        If an error occurs during the execution of a process, it handles the error.\n        Resets the current process to None after each execution.\n\n        Returns:\n            None\n        \"\"\"\n        for process in self._processes:\n            self._current_process = process\n            error = process.execute(self)\n            if error:\n                self._handle_error(error)\n            self._current_process = None\n\n    def _handle_error(self, error: Exception) -&gt; None:\n        \"\"\"\n        Handles errors that occur during the execution of a process.\n\n        Args:\n            error (Exception): The exception that was raised.\n\n        Raises:\n            BuilderError: If the error is an instance of BuilderError.\n            ExecutionError: If the error is not an instance of BuilderError,\n                            raises an ExecutionError with the current process name and the original error.\n        \"\"\"\n        if isinstance(error, BuilderError):\n            raise error\n\n        process_name = self._current_process.__class__.__name__\n        raise ExecutionError(process_name, error)\n\n    def get_permanences(self, name: str) -&gt; Any:\n        \"\"\"\n        Retrieve the permanence value associated with the given name.\n\n        Args:\n            name (str): The key name for which to retrieve the permanence value.\n        Returns:\n            Any: The permanence value associated with the given name.\n        Raises:\n            PermanenceKeyError: If the given name is not found in the permanences dictionary.\n        \"\"\"\n\n        if name not in self._permanences:\n            raise PermanenceKeyError(ErrorCode.PERMA_KEY, key=name)\n        return self._permanences[name]\n</code></pre>"},{"location":"modules/observer/#pytorchimagepipeline.observer.Observer.__init__","title":"<code>__init__(permanences)</code>","text":"<p>Initializes the Observer with the given permanences.</p> <p>Parameters:</p> Name Type Description Default <code>permanences</code> <code>dict[str, Permanence]</code> <p>A dictionary mapping string keys to Permanence objects.</p> required Source code in <code>pytorchimagepipeline/observer.py</code> <pre><code>def __init__(self, permanences: dict[str, Permanence]):\n    \"\"\"\n    Initializes the Observer with the given permanences.\n\n    Args:\n        permanences (dict[str, Permanence]): A dictionary mapping string keys to Permanence objects.\n    \"\"\"\n    self._permanences = permanences\n    self._processes: list[PipelineProcess] = []\n    self._current_process: Optional[PipelineProcess] = None\n</code></pre>"},{"location":"modules/observer/#pytorchimagepipeline.observer.Observer.add_process","title":"<code>add_process(process)</code>","text":"<p>Adds a process to the pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>process</code> <code>PipelineProcess</code> <p>The process to add.</p> required Source code in <code>pytorchimagepipeline/observer.py</code> <pre><code>def add_process(self, process: PipelineProcess) -&gt; None:\n    \"\"\"Adds a process to the pipeline.\n\n    Args:\n        process (PipelineProcess): The process to add.\n    \"\"\"\n    self._processes.append(process)\n</code></pre>"},{"location":"modules/observer/#pytorchimagepipeline.observer.Observer.get_permanences","title":"<code>get_permanences(name)</code>","text":"<p>Retrieve the permanence value associated with the given name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The key name for which to retrieve the permanence value.</p> required <p>Returns:     Any: The permanence value associated with the given name. Raises:     PermanenceKeyError: If the given name is not found in the permanences dictionary.</p> Source code in <code>pytorchimagepipeline/observer.py</code> <pre><code>def get_permanences(self, name: str) -&gt; Any:\n    \"\"\"\n    Retrieve the permanence value associated with the given name.\n\n    Args:\n        name (str): The key name for which to retrieve the permanence value.\n    Returns:\n        Any: The permanence value associated with the given name.\n    Raises:\n        PermanenceKeyError: If the given name is not found in the permanences dictionary.\n    \"\"\"\n\n    if name not in self._permanences:\n        raise PermanenceKeyError(ErrorCode.PERMA_KEY, key=name)\n    return self._permanences[name]\n</code></pre>"},{"location":"modules/observer/#pytorchimagepipeline.observer.Observer.run","title":"<code>run()</code>","text":"<p>Executes each process in the list of processes.</p> <p>Iterates over the processes, sets the current process, and executes it. If an error occurs during the execution of a process, it handles the error. Resets the current process to None after each execution.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>pytorchimagepipeline/observer.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"\n    Executes each process in the list of processes.\n\n    Iterates over the processes, sets the current process, and executes it.\n    If an error occurs during the execution of a process, it handles the error.\n    Resets the current process to None after each execution.\n\n    Returns:\n        None\n    \"\"\"\n    for process in self._processes:\n        self._current_process = process\n        error = process.execute(self)\n        if error:\n            self._handle_error(error)\n        self._current_process = None\n</code></pre>"}]}